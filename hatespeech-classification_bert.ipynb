{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data, drop empty Txt and Settings\n",
    "----"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        comment_text  toxic\n0  u created request scholarlyarticles awaiting c...      1\n1  looking lgbt profession category point get beh...      1\n2  new york city regulation regarding removal, , ...      0\n3  thank speedy rollback would believe first time...      1\n4  want talk stuff perfectly willing refer commen...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>u created request scholarlyarticles awaiting c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>looking lgbt profession category point get beh...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>new york city regulation regarding removal, , ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>thank speedy rollback would believe first time...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>want talk stuff perfectly willing refer commen...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SET_datapath = \"data_pp_cut.json\"\n",
    "\n",
    "SET_SVM_active = False\n",
    "\n",
    "df = pd.read_json(SET_datapath, orient=\"columns\")\n",
    "\n",
    "df.drop(df[df.comment_text.str.len() == 0].index, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Embedding\n",
    "\n",
    "----"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m encoded_comments \u001B[38;5;241m=\u001B[39m tokenizer(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcomment_text\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist(), padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Pass tokenized comments through BERT model to get embeddings\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m bert_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoded_comments\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpooler_output\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;03mimport torch\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124;03mfrom transformers import BertTokenizer, BertModel\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;124;03m    outputs = model(**encoded_comments)\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;124;03m    bert_embeddings = outputs.pooler_output.numpy()\"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\engine\\training.py:558\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    554\u001B[0m         \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(inputs, \u001B[38;5;241m*\u001B[39mcopied_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcopied_kwargs)\n\u001B[0;32m    556\u001B[0m     layout_map_lib\u001B[38;5;241m.\u001B[39m_map_subclass_model_variable(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layout_map)\n\u001B[1;32m--> 558\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1145\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1140\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[0;32m   1142\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object\n\u001B[0;32m   1144\u001B[0m ):\n\u001B[1;32m-> 1145\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m call_fn(inputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[0;32m   1148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     99\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:432\u001B[0m, in \u001B[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    429\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\n\u001B[0;32m    431\u001B[0m unpacked_inputs \u001B[38;5;241m=\u001B[39m input_processing(func, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfn_args_and_kwargs)\n\u001B[1;32m--> 432\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munpacked_inputs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:1114\u001B[0m, in \u001B[0;36mTFBertModel.call\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001B[0m\n\u001B[0;32m   1070\u001B[0m \u001B[38;5;129m@unpack_inputs\u001B[39m\n\u001B[0;32m   1071\u001B[0m \u001B[38;5;129m@add_start_docstrings_to_model_forward\u001B[39m(BERT_INPUTS_DOCSTRING\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size, sequence_length\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m   1072\u001B[0m \u001B[38;5;129m@add_code_sample_docstrings\u001B[39m(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1092\u001B[0m     training: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1093\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[TFBaseModelOutputWithPoolingAndCrossAttentions, Tuple[tf\u001B[38;5;241m.\u001B[39mTensor]]:\n\u001B[0;32m   1094\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1095\u001B[0m \u001B[38;5;124;03m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1096\u001B[0m \u001B[38;5;124;03m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1112\u001B[0m \u001B[38;5;124;03m        `past_key_values`). Set to `False` during training, `True` during generation\u001B[39;00m\n\u001B[0;32m   1113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1114\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1116\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1120\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1124\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1125\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1126\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1127\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1128\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1129\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1145\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1140\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[0;32m   1142\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object\n\u001B[0;32m   1144\u001B[0m ):\n\u001B[1;32m-> 1145\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m call_fn(inputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[0;32m   1148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     99\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:432\u001B[0m, in \u001B[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    429\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\n\u001B[0;32m    431\u001B[0m unpacked_inputs \u001B[38;5;241m=\u001B[39m input_processing(func, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfn_args_and_kwargs)\n\u001B[1;32m--> 432\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munpacked_inputs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:870\u001B[0m, in \u001B[0;36mTFBertMainLayer.call\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001B[0m\n\u001B[0;32m    867\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    868\u001B[0m     head_mask \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers\n\u001B[1;32m--> 870\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    872\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    873\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    884\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    885\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(hidden_states\u001B[38;5;241m=\u001B[39msequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1145\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1140\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[0;32m   1142\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object\n\u001B[0;32m   1144\u001B[0m ):\n\u001B[1;32m-> 1145\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m call_fn(inputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[0;32m   1148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     99\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:562\u001B[0m, in \u001B[0;36mTFBertEncoder.call\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001B[0m\n\u001B[0;32m    558\u001B[0m     all_hidden_states \u001B[38;5;241m=\u001B[39m all_hidden_states \u001B[38;5;241m+\u001B[39m (hidden_states,)\n\u001B[0;32m    560\u001B[0m past_key_value \u001B[38;5;241m=\u001B[39m past_key_values[i] \u001B[38;5;28;01mif\u001B[39;00m past_key_values \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 562\u001B[0m layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    563\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    564\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    565\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    566\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    567\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    568\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    569\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    570\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    571\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    572\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    574\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1145\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1140\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[0;32m   1142\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object\n\u001B[0;32m   1144\u001B[0m ):\n\u001B[1;32m-> 1145\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m call_fn(inputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[0;32m   1148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     99\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:518\u001B[0m, in \u001B[0;36mTFBertLayer.call\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001B[0m\n\u001B[0;32m    515\u001B[0m     cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    516\u001B[0m     present_key_value \u001B[38;5;241m=\u001B[39m present_key_value \u001B[38;5;241m+\u001B[39m cross_attn_present_key_value\n\u001B[1;32m--> 518\u001B[0m intermediate_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mintermediate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    519\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbert_output(\n\u001B[0;32m    520\u001B[0m     hidden_states\u001B[38;5;241m=\u001B[39mintermediate_output, input_tensor\u001B[38;5;241m=\u001B[39mattention_output, training\u001B[38;5;241m=\u001B[39mtraining\n\u001B[0;32m    521\u001B[0m )\n\u001B[0;32m    522\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m outputs  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1145\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1140\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[0;32m   1142\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object\n\u001B[0;32m   1144\u001B[0m ):\n\u001B[1;32m-> 1145\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m call_fn(inputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[0;32m   1148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     99\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:421\u001B[0m, in \u001B[0;36mTFBertIntermediate.call\u001B[1;34m(self, hidden_states)\u001B[0m\n\u001B[0;32m    420\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: tf\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m tf\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 421\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    422\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate_act_fn(hidden_states)\n\u001B[0;32m    424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1145\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1140\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[0;32m   1142\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object\n\u001B[0;32m   1144\u001B[0m ):\n\u001B[1;32m-> 1145\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m call_fn(inputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[0;32m   1148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     99\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\keras\\layers\\core\\dense.py:244\u001B[0m, in \u001B[0;36mDense.call\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m    241\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmatmul(a\u001B[38;5;241m=\u001B[39minputs, b\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel)\n\u001B[0;32m    242\u001B[0m \u001B[38;5;66;03m# Broadcast kernel to inputs.\u001B[39;00m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 244\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensordot\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mrank\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;66;03m# Reshape the output back to the original ndim of the input.\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[0;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:5160\u001B[0m, in \u001B[0;36mtensordot\u001B[1;34m(a, b, axes, name)\u001B[0m\n\u001B[0;32m   5157\u001B[0m a_reshape, a_free_dims, a_free_dims_static \u001B[38;5;241m=\u001B[39m _tensordot_reshape(a, a_axes)\n\u001B[0;32m   5158\u001B[0m b_reshape, b_free_dims, b_free_dims_static \u001B[38;5;241m=\u001B[39m _tensordot_reshape(\n\u001B[0;32m   5159\u001B[0m     b, b_axes, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m-> 5160\u001B[0m ab_matmul \u001B[38;5;241m=\u001B[39m \u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma_reshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb_reshape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(a_free_dims, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(b_free_dims, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m   5162\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (ab_matmul\u001B[38;5;241m.\u001B[39mget_shape()\u001B[38;5;241m.\u001B[39mis_fully_defined() \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m   5163\u001B[0m       ab_matmul\u001B[38;5;241m.\u001B[39mget_shape()\u001B[38;5;241m.\u001B[39mas_list() \u001B[38;5;241m==\u001B[39m a_free_dims \u001B[38;5;241m+\u001B[39m b_free_dims):\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[0;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3766\u001B[0m, in \u001B[0;36mmatmul\u001B[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001B[0m\n\u001B[0;32m   3763\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m gen_math_ops\u001B[38;5;241m.\u001B[39mbatch_mat_mul_v3(\n\u001B[0;32m   3764\u001B[0m       a, b, adj_x\u001B[38;5;241m=\u001B[39madjoint_a, adj_y\u001B[38;5;241m=\u001B[39madjoint_b, Tout\u001B[38;5;241m=\u001B[39moutput_type, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[0;32m   3765\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3766\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_math_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmat_mul\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3767\u001B[0m \u001B[43m      \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranspose_a\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtranspose_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranspose_b\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtranspose_b\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\nlp_p2\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6713\u001B[0m, in \u001B[0;36mmat_mul\u001B[1;34m(a, b, transpose_a, transpose_b, name)\u001B[0m\n\u001B[0;32m   6711\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   6712\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 6713\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   6714\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMatMul\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtranspose_a\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranspose_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtranspose_b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   6715\u001B[0m \u001B[43m      \u001B[49m\u001B[43mtranspose_b\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6716\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   6717\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize input comments\n",
    "for i in rang\n",
    "encoded_comments = tokenizer(df['comment_text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
    "\n",
    "# Pass tokenized comments through BERT model to get embeddings\n",
    "bert_embeddings = model(encoded_comments)['pooler_output'].numpy()\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize input comments\n",
    "encoded_comments = tokenizer(df['comment_text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "# Pass tokenized comments through BERT model to get embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_comments)\n",
    "    bert_embeddings = outputs.pooler_output.numpy()\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "batch_size = 2000\n",
    "bert_embeddings = []\n",
    "\n",
    "# Tokenize and process comments in batches\n",
    "for i in range(0, len(df), batch_size):\n",
    "    comments_batch = df['comment_text'].iloc[i:i+batch_size].tolist()\n",
    "    encoded_comments = tokenizer(comments_batch, padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
    "    batch_embeddings = model(encoded_comments)['pooler_output'].numpy()\n",
    "    bert_embeddings.append(batch_embeddings)\n",
    "\n",
    "# Concatenate embeddings from all batches\n",
    "bert_embeddings = np.concatenate(bert_embeddings, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split Data for Models\n",
    "----"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bert_embeddings, df['toxic'].values, test_size=0.2, random_state=99)\n",
    "\n",
    "# Scale input features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-08T09:06:44.894984Z",
     "iopub.execute_input": "2023-03-08T09:06:44.895705Z",
     "iopub.status.idle": "2023-03-08T09:06:44.902237Z",
     "shell.execute_reply.started": "2023-03-08T09:06:44.895669Z",
     "shell.execute_reply": "2023-03-08T09:06:44.900681Z"
    },
    "trusted": true,
    "id": "BXQp4lTzC1OK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Models and get Scores\n",
    "\n",
    "----"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Try... Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# load the 20 newsgroups dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "# convert text to numerical data\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(newsgroups_train.data)\n",
    "X_train = tokenizer.texts_to_matrix(newsgroups_train.data, mode='tfidf')\n",
    "X_test = tokenizer.texts_to_matrix(newsgroups_test.data, mode='tfidf')\n",
    "\n",
    "# convert labels to categorical data\n",
    "num_classes = np.max(newsgroups_train.target) + 1\n",
    "y_train = to_categorical(newsgroups_train.target, num_classes)\n",
    "y_test = to_categorical(newsgroups_test.target, num_classes)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(2000,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "#model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_test, y_test))\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import csv\n",
    "def model_train(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_tr = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test,y_pred)\n",
    "    recall = report.split()[-2]\n",
    "    print(\"--------------------Training Performance---------------------\")\n",
    "    print(accuracy_score(y_train,y_pred_tr))\n",
    "    print(classification_report(y_train,y_pred_tr))\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "    print(\"--------------------Testing Performance----------------------\")\n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred),cmap='viridis',annot=True,fmt='.4g')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.show()\n",
    "\n",
    "    # Save recall value in a CSV file\n",
    "    model_name = \"bert_\" + model.__class__.__name__\n",
    "    new_recall = recall\n",
    "\n",
    "    # read existing data from csv file\n",
    "    existing_data = []\n",
    "    with open(\"performance.csv\", mode=\"r\") as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            existing_data.append(row)\n",
    "\n",
    "    # update recall value if modelname already exists\n",
    "    for row in existing_data:\n",
    "        if row[\"Model\"] == model_name:\n",
    "            row[\"Recall\"] = new_recall\n",
    "\n",
    "    # write data back to csv file\n",
    "    with open(\"performance.csv\", mode=\"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=[\"Model\", \"Recall\"])\n",
    "        writer.writeheader()\n",
    "        for row in existing_data:\n",
    "            writer.writerow(row)\n",
    "        # write new row if model doesn't exist\n",
    "        if model_name not in [row[\"Model\"] for row in existing_data]:\n",
    "            writer.writerow({\"Model\": model_name, \"Recall\": new_recall})"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-08T09:06:48.069063Z",
     "iopub.execute_input": "2023-03-08T09:06:48.069767Z",
     "iopub.status.idle": "2023-03-08T09:06:48.077451Z",
     "shell.execute_reply.started": "2023-03-08T09:06:48.069730Z",
     "shell.execute_reply": "2023-03-08T09:06:48.076100Z"
    },
    "trusted": true,
    "id": "eB0eFrl8C1OK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Naive Bayes:"
   ],
   "metadata": {
    "id": "tfuKOJNrC1OL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "modelNB = MultinomialNB()\n",
    "model_train(modelNB, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-08T08:07:23.062257Z",
     "iopub.execute_input": "2023-03-08T08:07:23.062625Z",
     "iopub.status.idle": "2023-03-08T08:07:24.144923Z",
     "shell.execute_reply.started": "2023-03-08T08:07:23.062594Z",
     "shell.execute_reply": "2023-03-08T08:07:24.143947Z"
    },
    "trusted": true,
    "id": "UzFW6F2_C1OM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Support Vector Machine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SET_SVM_active:\n",
    "    from sklearn.svm import SVC\n",
    "    modelSVM = SVC()\n",
    "    model_train(modelSVM, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression (Best Model) :"
   ],
   "metadata": {
    "id": "eR4604KRC1OM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "modelLR = LogisticRegression(max_iter=1000)\n",
    "model_train(modelLR, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-08T08:09:56.827671Z",
     "iopub.execute_input": "2023-03-08T08:09:56.828070Z",
     "iopub.status.idle": "2023-03-08T08:11:11.443944Z",
     "shell.execute_reply.started": "2023-03-08T08:09:56.828032Z",
     "shell.execute_reply": "2023-03-08T08:11:11.442942Z"
    },
    "trusted": true,
    "id": "KkkTCParC1OM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest:"
   ],
   "metadata": {
    "id": "bEGUQQvkC1OM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = RandomForestClassifier(n_estimators=100,max_depth=15,max_features='sqrt')\n",
    "model_train(model, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-08T08:20:13.896081Z",
     "iopub.execute_input": "2023-03-08T08:20:13.896506Z",
     "iopub.status.idle": "2023-03-08T08:20:37.522992Z",
     "shell.execute_reply.started": "2023-03-08T08:20:13.896471Z",
     "shell.execute_reply": "2023-03-08T08:20:37.521949Z"
    },
    "trusted": true,
    "id": "2mjAK3ZTC1ON"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"finished\")"
   ],
   "metadata": {
    "id": "A7KILiHlC1ON"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
